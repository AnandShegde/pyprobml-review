{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eef6318",
   "metadata": {},
   "source": [
    "# Application of Zipf's law on H. G. Wells' The Time Machine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a610c3c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FIG_DIR=latex\n",
      "env: LATEXIFY=1\n"
     ]
    }
   ],
   "source": [
    "# Modified from\n",
    "# https://github.com/d2l-ai/d2l-en/blob/master/chapter_recurrent-neural-networks/lang-model.md\n",
    "# D2L sec 8.2\n",
    "\n",
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from probml_utils import savefig, latexify, is_latexify_enabled\n",
    "except ModuleNotFoundError:\n",
    "    %pip install git+https://github.com/probml/probml-utils.git\n",
    "    from probml_utils import savefig, latexify, is_latexify_enabled\n",
    "import collections\n",
    "import re\n",
    "import os\n",
    "try:\n",
    "    import requests\n",
    "except:\n",
    "    %pip install -qq requests\n",
    "    import requests\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6afac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latexify(width_scale_factor=1.70, fig_height=2.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f79466b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "[]\n",
      "['i']\n",
      "[]\n",
      "['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him', 'was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and', 'twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the', 'fire', 'burned', 'brightly', 'and', 'the', 'soft', 'radiance', 'of', 'the', 'incandescent', 'lights', 'in', 'the', 'lilies', 'of', 'silver', 'caught', 'the', 'bubbles', 'that', 'flashed', 'and', 'passed', 'in', 'our', 'glasses', 'our', 'chairs', 'being', 'his', 'patents', 'embraced', 'and', 'caressed', 'us', 'rather', 'than', 'submitted', 'to', 'be', 'sat', 'upon', 'and', 'there', 'was', 'that', 'luxurious', 'after', 'dinner', 'atmosphere', 'when', 'thought', 'roams', 'gracefully', 'free', 'of', 'the', 'trammels', 'of', 'precision', 'and', 'he', 'put', 'it', 'to', 'us', 'in', 'this', 'way', 'marking', 'the', 'points', 'with', 'a', 'lean', 'forefinger', 'as', 'we', 'sat', 'and', 'lazily', 'admired', 'his', 'earnestness', 'over', 'this', 'new', 'paradox', 'as', 'we', 'thought', 'it', 'and', 'his', 'fecundity']\n",
      "[]\n",
      "['you', 'must', 'follow', 'me', 'carefully', 'i', 'shall', 'have', 'to', 'controvert', 'one', 'or', 'two', 'ideas', 'that', 'are', 'almost', 'universally', 'accepted', 'the', 'geometry', 'for', 'instance', 'they', 'taught', 'you', 'at', 'school', 'is', 'founded', 'on', 'a', 'misconception']\n",
      "[]\n",
      "['is', 'not', 'that', 'rather', 'a', 'large', 'thing', 'to', 'expect', 'us', 'to', 'begin', 'upon', 'said', 'filby', 'an', 'argumentative', 'person', 'with', 'red', 'hair']\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\\n[]\\n['i']\\n[]\\n['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him', 'was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and', 'twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the', 'fire', 'burned', 'brightly', 'and', 'the', 'soft', 'radiance', 'of', 'the', 'incandescent', 'lights', 'in', 'the', 'lilies', 'of', 'silver', 'caught', 'the', 'bubbles', 'that', 'flashed', 'and', 'passed', 'in', 'our', 'glasses', 'our', 'chairs', 'being', 'his', 'patents', 'embraced', 'and', 'caressed', 'us', 'rather', 'than', 'submitted', 'to', 'be', 'sat', 'upon', 'and', 'there', 'was', 'that', 'luxurious', 'after', 'dinner', 'atmosphere', 'when', 'thought', 'roams', 'gracefully', 'free', 'of', 'the', 'trammels', 'of', 'precision', 'and', 'he', 'put', 'it', 'to', 'us', 'in', 'this', 'way', 'marking', 'the', 'points', 'with', 'a', 'lean', 'forefinger', 'as', 'we', 'sat', 'and', 'lazily', 'admired', 'his', 'earnestness', 'over', 'this', 'new', 'paradox', 'as', 'we', 'thought', 'it', 'and', 'his', 'fecundity']\\n[]\\n['you', 'must', 'follow', 'me', 'carefully', 'i', 'shall', 'have', 'to', 'controvert', 'one', 'or', 'two', 'ideas', 'that', 'are', 'almost', 'universally', 'accepted', 'the', 'geometry', 'for', 'instance', 'they', 'taught', 'you', 'at', 'school', 'is', 'founded', 'on', 'a', 'misconception']\\n[]\\n['is', 'not', 'that', 'rather', 'a', 'large', 'thing', 'to', 'expect', 'us', 'to', 'begin', 'upon', 'said', 'filby', 'an', 'argumentative', 'person', 'with', 'red', 'hair']\\n[]\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webdata = True\n",
    "\n",
    "if webdata:\n",
    "    url = \"https://raw.githubusercontent.com/probml/probml-data/main/data/timemachine.txt\"\n",
    "    response = requests.get(url)\n",
    "    data = response.text\n",
    "    lines = [s + \"\\n\" for s in response.text.split(\"\\n\")]\n",
    "else:\n",
    "    data_dir = \"../data\"\n",
    "    fname = os.path.join(data_dir, \"timemachine.txt\")\n",
    "    with open(fname, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "raw_dataset = [re.sub(\"[^A-Za-z]+\", \" \", st).lower().split() for st in lines]\n",
    "\n",
    "# Print first few lines\n",
    "for sentence in raw_dataset[:10]:\n",
    "    print(sentence)\n",
    "\"\"\"\n",
    "['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
    "[]\n",
    "['i']\n",
    "[]\n",
    "['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him', 'was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and', 'twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the', 'fire', 'burned', 'brightly', 'and', 'the', 'soft', 'radiance', 'of', 'the', 'incandescent', 'lights', 'in', 'the', 'lilies', 'of', 'silver', 'caught', 'the', 'bubbles', 'that', 'flashed', 'and', 'passed', 'in', 'our', 'glasses', 'our', 'chairs', 'being', 'his', 'patents', 'embraced', 'and', 'caressed', 'us', 'rather', 'than', 'submitted', 'to', 'be', 'sat', 'upon', 'and', 'there', 'was', 'that', 'luxurious', 'after', 'dinner', 'atmosphere', 'when', 'thought', 'roams', 'gracefully', 'free', 'of', 'the', 'trammels', 'of', 'precision', 'and', 'he', 'put', 'it', 'to', 'us', 'in', 'this', 'way', 'marking', 'the', 'points', 'with', 'a', 'lean', 'forefinger', 'as', 'we', 'sat', 'and', 'lazily', 'admired', 'his', 'earnestness', 'over', 'this', 'new', 'paradox', 'as', 'we', 'thought', 'it', 'and', 'his', 'fecundity']\n",
    "[]\n",
    "['you', 'must', 'follow', 'me', 'carefully', 'i', 'shall', 'have', 'to', 'controvert', 'one', 'or', 'two', 'ideas', 'that', 'are', 'almost', 'universally', 'accepted', 'the', 'geometry', 'for', 'instance', 'they', 'taught', 'you', 'at', 'school', 'is', 'founded', 'on', 'a', 'misconception']\n",
    "[]\n",
    "['is', 'not', 'that', 'rather', 'a', 'large', 'thing', 'to', 'expect', 'us', 'to', 'begin', 'upon', 'said', 'filby', 'an', 'argumentative', 'person', 'with', 'red', 'hair']\n",
    "[]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040e7a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 unigrams\n",
      " ['the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'the', 'time']\n",
      "First 10 bigrams\n",
      " [('the', 'time'), ('time', 'machine'), ('machine', 'by'), ('by', 'h'), ('h', 'g'), ('g', 'wells'), ('wells', 'i'), ('i', 'the'), ('the', 'time'), ('time', 'traveller')]\n",
      "First 10 trigrams\n",
      " [('the', 'time', 'machine'), ('time', 'machine', 'by'), ('machine', 'by', 'h'), ('by', 'h', 'g'), ('h', 'g', 'wells'), ('g', 'wells', 'i'), ('wells', 'i', 'the'), ('i', 'the', 'time'), ('the', 'time', 'traveller'), ('time', 'traveller', 'for')]\n",
      "Most common unigrams\n",
      " [('the', 2261), ('i', 1267), ('and', 1245), ('of', 1155), ('a', 816), ('to', 695), ('was', 552), ('in', 541), ('that', 443), ('my', 440)]\n",
      "Most common bigrams\n",
      " [(('of', 'the'), 309), (('in', 'the'), 169), (('i', 'had'), 130), (('i', 'was'), 112), (('and', 'the'), 109), (('the', 'time'), 102), (('it', 'was'), 99), (('to', 'the'), 85), (('as', 'i'), 78), (('of', 'a'), 73)]\n",
      "Most common trigrams\n",
      " [(('the', 'time', 'traveller'), 59), (('the', 'time', 'machine'), 30), (('the', 'medical', 'man'), 24), (('it', 'seemed', 'to'), 16), (('it', 'was', 'a'), 15), (('here', 'and', 'there'), 15), (('seemed', 'to', 'me'), 14), (('i', 'did', 'not'), 14), (('i', 'saw', 'the'), 13), (('i', 'began', 'to'), 13)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nFirst 10 unigrams\\n ['the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'the', 'time']\\nFirst 10 bigrams\\n [('the', 'time'), ('time', 'machine'), ('machine', 'by'), ('by', 'h'), ('h', 'g'), ('g', 'wells'), ('wells', 'i'), ('i', 'the'), ('the', 'time'), ('time', 'traveller')]\\nFirst 10 trigrams\\n [('the', 'time', 'machine'), ('time', 'machine', 'by'), ('machine', 'by', 'h'), ('by', 'h', 'g'), ('h', 'g', 'wells'), ('g', 'wells', 'i'), ('wells', 'i', 'the'), ('i', 'the', 'time'), ('the', 'time', 'traveller'), ('time', 'traveller', 'for')]\\nMost common unigrams\\n [('the', 2261), ('i', 1267), ('and', 1245), ('of', 1155), ('a', 816), ('to', 695), ('was', 552), ('in', 541), ('that', 443), ('my', 440)]\\nMost common bigrams\\n [(('of', 'the'), 309), (('in', 'the'), 169), (('i', 'had'), 130), (('i', 'was'), 112), (('and', 'the'), 109), (('the', 'time'), 102), (('it', 'was'), 99), (('to', 'the'), 85), (('as', 'i'), 78), (('of', 'a'), 73)]\\nMost common trigrams\\n [(('the', 'time', 'traveller'), 59), (('the', 'time', 'machine'), 30), (('the', 'medical', 'man'), 24), (('it', 'seemed', 'to'), 16), (('it', 'was', 'a'), 15), (('here', 'and', 'there'), 15), (('seemed', 'to', 'me'), 14), (('i', 'did', 'not'), 14), (('i', 'saw', 'the'), 13), (('i', 'began', 'to'), 13)]\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unigrams\n",
    "words = [word for sentence in raw_dataset for word in sentence]\n",
    "print(\"First 10 unigrams\\n\", words[:10])\n",
    "\n",
    "# Bigrams\n",
    "word_pairs = [pair for pair in zip(words[:-1], words[1:])]\n",
    "print(\"First 10 bigrams\\n\", word_pairs[:10])\n",
    "\n",
    "# Trigrams\n",
    "word_triples = [triple for triple in zip(words[:-2], words[1:-1], words[2:])]\n",
    "print(\"First 10 trigrams\\n\", word_triples[:10])\n",
    "\n",
    "# ngram statistics\n",
    "counter = collections.Counter(words)\n",
    "counter_pairs = collections.Counter(word_pairs)\n",
    "counter_triples = collections.Counter(word_triples)\n",
    "\n",
    "print(\"Most common unigrams\\n\", counter.most_common(10))\n",
    "print(\"Most common bigrams\\n\", counter_pairs.most_common(10))\n",
    "print(\"Most common trigrams\\n\", counter_triples.most_common(10))\n",
    "\n",
    "wordcounts = jnp.array([count for _, count in counter.most_common()])\n",
    "bigramcounts = jnp.array([count for _, count in counter_pairs.most_common()])\n",
    "triplecounts = jnp.array([count for _, count in counter_triples.most_common()])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "First 10 unigrams\n",
    " ['the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'the', 'time']\n",
    "First 10 bigrams\n",
    " [('the', 'time'), ('time', 'machine'), ('machine', 'by'), ('by', 'h'), ('h', 'g'), ('g', 'wells'), ('wells', 'i'), ('i', 'the'), ('the', 'time'), ('time', 'traveller')]\n",
    "First 10 trigrams\n",
    " [('the', 'time', 'machine'), ('time', 'machine', 'by'), ('machine', 'by', 'h'), ('by', 'h', 'g'), ('h', 'g', 'wells'), ('g', 'wells', 'i'), ('wells', 'i', 'the'), ('i', 'the', 'time'), ('the', 'time', 'traveller'), ('time', 'traveller', 'for')]\n",
    "Most common unigrams\n",
    " [('the', 2261), ('i', 1267), ('and', 1245), ('of', 1155), ('a', 816), ('to', 695), ('was', 552), ('in', 541), ('that', 443), ('my', 440)]\n",
    "Most common bigrams\n",
    " [(('of', 'the'), 309), (('in', 'the'), 169), (('i', 'had'), 130), (('i', 'was'), 112), (('and', 'the'), 109), (('the', 'time'), 102), (('it', 'was'), 99), (('to', 'the'), 85), (('as', 'i'), 78), (('of', 'a'), 73)]\n",
    "Most common trigrams\n",
    " [(('the', 'time', 'traveller'), 59), (('the', 'time', 'machine'), 30), (('the', 'medical', 'man'), 24), (('it', 'seemed', 'to'), 16), (('it', 'was', 'a'), 15), (('here', 'and', 'there'), 15), (('seemed', 'to', 'me'), 14), (('i', 'did', 'not'), 14), (('i', 'saw', 'the'), 13), (('i', 'began', 'to'), 13)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b21611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving image to latex/timemachine-zipf-1_latexified\n",
      "Figure size: [3.52941176 2.25      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6727/1142724243.py:15: UserWarning: Matplotlib is currently using ps, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.loglog(wordcounts, label=\"word counts\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(\"rank\")\n",
    "c = 10.0\n",
    "x = jnp.arange(c, len(wordcounts))  # rank\n",
    "N = jnp.sum(wordcounts)\n",
    "kappa = 0.1\n",
    "a = -1\n",
    "y = kappa * jnp.power(x, a) * N  # predicted frequencey\n",
    "plt.loglog(x, y, label=\"linear prediction\")\n",
    "plt.legend()\n",
    "\n",
    "savefig(\"timemachine-zipf-1_latexified\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d53cdccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving image to latex/timemachine-zipf-3_latexified\n",
      "Figure size: [3.52941176 2.25      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6727/1901158262.py:9: UserWarning: Matplotlib is currently using ps, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.loglog(wordcounts, label=\"word counts\")\n",
    "plt.loglog(bigramcounts, label=\"bigram counts\")\n",
    "plt.loglog(triplecounts, label=\"triple counts\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(\"rank\")\n",
    "savefig(\"timemachine-zipf-3_latexified\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
